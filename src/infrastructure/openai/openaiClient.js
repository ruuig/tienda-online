// Cliente para integraci칩n con OpenAI GPT-4
import OpenAI from 'openai';
import { createPromptConfigService } from '@/src/services/promptConfigService.js';

const promptConfigService = createPromptConfigService();
const OFF_TOPIC_TEMPLATE = promptConfigService.getPrompt('offTopicResponse')?.content ||
  '춰Hola! 游땕 Soy un asistente especializado 칰nicamente en productos tecnol칩gicos y compras en nuestra tienda online. ' +
  'Para preguntas sobre {TOPIC}, te recomiendo consultar fuentes especializadas. 쯊e puedo ayudar con smartphones, laptops, aud칤fonos u otros productos electr칩nicos? 游';

export class OpenAIClient {
  constructor(apiKey) {
    if (!apiKey) {
      throw new Error('OpenAI API key is required');
    }

    this.client = new OpenAI({
      apiKey,
      timeout: 30000, // 30 segundos timeout
    });

    this.model = 'gpt-4'; // Usar GPT-4 para mejores respuestas
    this.maxTokens = 500; // Limitar tokens para respuestas concisas
    this.temperature = 0.7; // Balance entre creatividad y consistencia
  }

  /**
   * Genera una respuesta usando GPT-4
   * @param {Array} messages - Array de mensajes en formato OpenAI
   * @param {Object} context - Contexto adicional (productos, documentos RAG, etc.)
   * @returns {Promise<string>} - Respuesta generada
   */
  async generateResponse(messages, context = {}) {
    try {
      console.log('OpenAIClient: Generando respuesta...');
      console.log('OpenAIClient: N칰mero de mensajes:', messages.length);
      console.log('OpenAIClient: Contexto recibido:', Object.keys(context));

      // Construir mensajes con contexto del sistema
      const systemMessage = this.buildSystemMessage(context);
      const messagesWithContext = [systemMessage, ...messages];

      console.log('OpenAIClient: Mensajes para OpenAI:', messagesWithContext.length);
      console.log('OpenAIClient: Enviando solicitud a OpenAI...');

      const response = await this.client.chat.completions.create({
        model: this.model,
        messages: messagesWithContext,
        max_tokens: this.maxTokens,
        temperature: this.temperature,
        top_p: 1,
        frequency_penalty: 0,
        presence_penalty: 0,
        stream: false // No usar streaming por simplicidad
      });

      console.log('OpenAIClient: Respuesta recibida de OpenAI');
      const generatedText = response.choices[0]?.message?.content?.trim();
      console.log('OpenAIClient: Texto generado:', generatedText?.substring(0, 100));

      if (!generatedText) {
        throw new Error('No se pudo generar una respuesta v치lida');
      }

      return generatedText;

    } catch (error) {
      console.error('OpenAIClient: Error generando respuesta:', error);
      console.error('OpenAIClient: Error code:', error.code);
      console.error('OpenAIClient: Error message:', error.message);

      // Manejar diferentes tipos de errores
      if (error.code === 'rate_limit_exceeded') {
        throw new Error('L칤mite de consultas excedido. Int칠ntalo m치s tarde.');
      }

      if (error.code === 'insufficient_quota') {
        throw new Error('Cuota de OpenAI insuficiente. Contacta al administrador.');
      }

      if (error.code === 'invalid_api_key') {
        throw new Error('Error de configuraci칩n de OpenAI. Contacta al administrador.');
      }

      throw new Error('Error generando respuesta autom치tica. Un agente te ayudar치 pronto.');
    }
  }

  /**
   * Construye el mensaje del sistema con contexto de la tienda
   * @param {Object} context - Informaci칩n contextual
   * @returns {Object} - Mensaje del sistema
   */
  buildSystemMessage(context) {
    const baseInstructions = `Eres un asistente de atenci칩n al cliente para una tienda online de tecnolog칤a.

INSTRUCCIONES:
- S칠 amable, profesional y 칰til
- Responde en espa침ol de manera clara y concisa
- Si no sabes algo, di "D칠jame consultar con un agente especializado"
- Para consultas t칠cnicas, proporciona informaci칩n precisa basada en documentos disponibles
- Nunca inventes informaci칩n sobre productos o pol칤ticas
- Si la consulta es sobre temas que NO est치n relacionados con la tienda ni la tecnolog칤a, rech치zala amablemente usando exactamente este mensaje (reemplaza {TOPIC} por el tema mencionado): "${OFF_TOPIC_TEMPLATE}"

CONTEXTO DE LA TIENDA:
- Somos especialistas en tecnolog칤a y productos electr칩nicos
- Ofrecemos garant칤a en todos nuestros productos
- Env칤o gratuito en compras mayores a Q500
- Pol칤ticas de devoluci칩n: 30 d칤as para productos sin usar

${context.products ? `PRODUCTOS DISPONIBLES: ${JSON.stringify(context.products.slice(0, 5))}` : ''}
${context.documents ? `INFORMACI칍N DE SOPORTE: ${context.documents.map(d => d.title).join(', ')}` : ''}

Responde siempre de manera 칰til y orientada al cliente.`;

    return {
      role: 'system',
      content: baseInstructions
    };
  }

  /**
   * Procesa una consulta con informaci칩n RAG
   * @param {string} query - Consulta del usuario
   * @param {Array} relevantDocuments - Documentos relevantes encontrados
   * @returns {Promise<string>} - Respuesta generada
   */
  async generateRAGResponse(query, relevantDocuments = []) {
    try {
      const context = {
        documents: relevantDocuments.map(doc => ({
          title: doc.title,
          content: doc.content.substring(0, 500), // Limitar tama침o
          category: doc.category,
          type: doc.type
        }))
      };

      const messages = [
        {
          role: 'user',
          content: `Consulta del cliente: ${query}\n\nInformaci칩n relevante encontrada:\n${relevantDocuments.map((doc, i) => `[${i+1}] ${doc.title}: ${doc.content.substring(0, 300)}...`).join('\n')}`
        }
      ];

      return await this.generateResponse(messages, context);

    } catch (error) {
      console.error('Error generando respuesta RAG:', error);
      throw new Error('Error procesando consulta con documentos de soporte');
    }
  }

  /**
   * Genera sugerencias de respuesta para agentes humanos
   * @param {string} customerQuery - Consulta del cliente
   * @param {Array} conversationHistory - Historial de conversaci칩n
   * @returns {Promise<Array>} - Array de sugerencias
   */
  async generateResponseSuggestions(customerQuery, conversationHistory = []) {
    try {
      const messages = [
        {
          role: 'system',
          content: 'Eres un asistente que genera sugerencias de respuesta para agentes de atenci칩n al cliente. Genera 3 respuestas cortas y 칰tiles diferentes para la consulta del cliente.'
        },
        {
          role: 'user',
          content: `Consulta del cliente: ${customerQuery}\n\nHistorial de conversaci칩n:\n${conversationHistory.slice(-3).map(m => `${m.sender}: ${m.content}`).join('\n')}`
        }
      ];

      const response = await this.client.chat.completions.create({
        model: this.model,
        messages,
        max_tokens: 300,
        temperature: 0.8,
        n: 3 // Generar 3 sugerencias
      });

      return response.choices.map(choice => choice.message.content.trim());

    } catch (error) {
      console.error('Error generando sugerencias:', error);
      return [
        'Lo siento, no pude generar sugerencias en este momento.',
        'Un agente especializado te ayudar치 con tu consulta.',
        'Gracias por tu paciencia mientras te conectamos con soporte.'
      ];
    }
  }

  /**
   * Clasifica la intenci칩n de la consulta del usuario
   * @param {string} message - Mensaje del usuario
   * @returns {Promise<Object>} - Objeto con intenci칩n y confianza
   */
  async classifyIntent(message) {
    try {
      console.log('OpenAIClient: Clasificando intenci칩n para mensaje:', message.substring(0, 50));

      const messages = [
        {
          role: 'system',
          content: `Clasifica la intenci칩n del mensaje del cliente en una de estas categor칤as:

          CATEGOR칈AS DE CONSULTA:
          - consulta_producto: Preguntas sobre productos espec칤ficos o cat치logo general
          - consulta_pedido: Seguimiento de pedidos o problemas con 칩rdenes existentes
          - consulta_tecnica: Problemas t칠cnicos o soporte t칠cnico
          - consulta_devolucion: Pol칤ticas de devoluci칩n o cambios
          - consulta_envio: Informaci칩n sobre env칤os y entregas
          - saludo: Saludos o conversaciones casuales
          - queja: Quejas o problemas con el servicio

          CATEGOR칈AS DE COMPRA CONVERSACIONAL:
          - compra_producto: Quiere comprar un producto espec칤fico que mencion칩
          - agregar_carrito: Quiere agregar productos al carrito de compra
          - ver_carrito: Quiere ver el contenido del carrito
          - modificar_carrito: Quiere cambiar cantidades o remover productos del carrito
          - proceder_pago: Quiere proceder al pago o finalizar la compra
          - confirmar_compra: Confirmaci칩n de detalles antes de comprar
          - cancelar_compra: Quiere cancelar el proceso de compra

          OTRAS:
          - otra: Cualquier otra consulta que no encaje en las categor칤as anteriores

          REGLAS ESPEC칈FICAS PARA COMPRA:
          - Si menciona un producto espec칤fico y dice "comprar", "adquirir", "me interesa", usa "compra_producto"
          - Si dice "agregar al carrito", "a침adir al carrito", usa "agregar_carrito"
          - Si dice "ver carrito", "qu칠 tengo en el carrito", usa "ver_carrito"
          - Si dice "proceder al pago", "pagar", "checkout", usa "proceder_pago"
          - Si pregunta por precios o disponibilidad con intenci칩n clara de compra, usa "compra_producto"

          Responde 칰nicamente con el formato JSON: {"intent": "categoria", "confidence": 0.95}`
        },
        {
          role: 'user',
          content: message
        }
      ];

      console.log('OpenAIClient: Enviando solicitud de clasificaci칩n a OpenAI...');
      const response = await this.client.chat.completions.create({
        model: this.model,
        messages,
        max_tokens: 50,
        temperature: 0.3,
        response_format: { type: "json_object" }
      });

      console.log('OpenAIClient: Respuesta de clasificaci칩n recibida');
      const result = JSON.parse(response.choices[0]?.message?.content || '{"intent": "otra", "confidence": 0.5}');

      return {
        intent: result.intent || 'otra',
        confidence: result.confidence || 0.5
      };

    } catch (error) {
      console.error('OpenAIClient: Error clasificando intenci칩n:', error);
      return {
        intent: 'otra',
        confidence: 0.5
      };
    }
  }

  /**
   * Verifica el estado de la API de OpenAI
   * @returns {Promise<boolean>} - True si la API est치 disponible
   */
  async checkHealth() {
    try {
      await this.client.models.list();
      return true;
    } catch (error) {
      console.error('Error verificando salud de OpenAI:', error);
      return false;
    }
  }
}

// Factory function para crear cliente OpenAI con configuraci칩n
export const createOpenAIClient = (apiKey) => {
  return new OpenAIClient(apiKey);
};
