// Cliente para integraci√≥n con OpenAI GPT-4
import OpenAI from 'openai';
import { createPromptConfigService } from '@/src/services/promptConfigService.js';

const promptConfigService = createPromptConfigService();
const OFF_TOPIC_TEMPLATE = '¬°Hola! üòä Soy un asistente especializado √∫nicamente en productos tecnol√≥gicos y compras en RJG Tech Shop. Para preguntas sobre {TOPIC}, te recomiendo consultar fuentes especializadas. ¬øTe puedo ayudar con smartphones, laptops, aud√≠fonos u otros productos electr√≥nicos? üõí';

export class OpenAIClient {
  constructor(apiKey) {
    if (!apiKey) {
      throw new Error('OpenAI API key is required');
    }

    this.client = new OpenAI({
      apiKey,
      timeout: 8000, // 8 segundos timeout (reducido de 30s)
    });

    this.model = 'gpt-3.5-turbo'; // Usar GPT-3.5-turbo para respuestas m√°s r√°pidas
    this.maxTokens = 200; // Reducir tokens para respuestas m√°s concisas y r√°pidas
    this.temperature = 0.7; // Balance entre creatividad y consistencia
  }

  /**
   * Genera una respuesta usando GPT-3.5-turbo
   * @param {Array} messages - Array de mensajes en formato OpenAI
   * @param {Object} context - Contexto adicional (productos, documentos RAG, etc.)
   * @returns {Promise<string>} - Respuesta generada
   */
  async generateResponse(messages, context = {}) {
    try {
      console.log('OpenAIClient: Generando respuesta...');
      console.log('OpenAIClient: N√∫mero de mensajes:', messages.length);
      console.log('OpenAIClient: Contexto recibido:', Object.keys(context));

      // Construir mensajes con contexto del sistema
      const systemMessage = this.buildSystemMessage(context);
      const messagesWithContext = [systemMessage, ...messages];

      console.log('OpenAIClient: Mensajes para OpenAI:', messagesWithContext.length);
      console.log('OpenAIClient: Enviando solicitud a OpenAI...');

      const response = await this.client.chat.completions.create({
        model: this.model,
        messages: messagesWithContext,
        max_tokens: this.maxTokens, // 200 tokens para respuestas r√°pidas
        temperature: this.temperature,
        top_p: 1,
        frequency_penalty: 0,
        presence_penalty: 0,
        stream: false // No usar streaming por simplicidad
      });

      console.log('OpenAIClient: Respuesta recibida de OpenAI');
      const generatedText = response.choices[0]?.message?.content?.trim();
      console.log('OpenAIClient: Texto generado:', generatedText?.substring(0, 100));

      if (!generatedText) {
        throw new Error('No se pudo generar una respuesta v√°lida');
      }

      return generatedText;

    } catch (error) {
      console.error('OpenAIClient: Error generando respuesta:', error);
      console.error('OpenAIClient: Error code:', error.code);
      console.error('OpenAIClient: Error message:', error.message);

      // Manejar diferentes tipos de errores
      if (error.code === 'rate_limit_exceeded') {
        throw new Error('L√≠mite de consultas excedido. Int√©ntalo m√°s tarde.');
      }

      if (error.code === 'insufficient_quota') {
        throw new Error('Cuota de OpenAI insuficiente. Contacta al administrador.');
      }

      if (error.code === 'invalid_api_key') {
        throw new Error('Error de configuraci√≥n de OpenAI. Contacta al administrador.');
      }

      throw new Error('Error generando respuesta autom√°tica. Un agente te ayudar√° pronto.');
    }
  }

  /**
   * Construye el mensaje del sistema con contexto de RJG Tech Shop
   * @param {Object} context - Informaci√≥n contextual
   * @returns {Object} - Mensaje del sistema
   */
  buildSystemMessage(context) {
    const ragSnippets = Array.isArray(context?.ragSnippets) ? context.ragSnippets : [];

    const ragDetails = ragSnippets.length > 0
      ? `\n\nINFO RELEVANTE:\n${ragSnippets.slice(0, 1).map(snippet => `[#${snippet.index}] ${snippet.title}${snippet.source ? ` (${snippet.source})` : ''}\n${snippet.excerpt.substring(0, 100)}...`).join('\n\n')}`
      : '';

    const baseInstructions = `Eres un asistente de atenci√≥n al cliente para RJG Tech Shop, una tienda online especializada en tecnolog√≠a y productos electr√≥nicos.

üéØ PERSONALIDAD Y TONO:
- S√© amable, profesional y servicial
- Responde en espa√±ol de manera clara y concisa
- Mant√©n un tono profesional y servicial
- NUNCA hagas bromas, chistes o comentarios informales
- Evita respuestas especulativas o informaci√≥n falsa

üè¨ INFORMACI√ìN DE RJG TECH SHOP:
Somos una tienda online especializada en tecnolog√≠a y productos electr√≥nicos, comprometidos con brindar la mejor experiencia de compra.

üéØ MISI√ìN:
Proporcionar productos tecnol√≥gicos de alta calidad, con servicio excepcional y precios competitivos, haciendo que la tecnolog√≠a sea accesible para todos.

üëÅÔ∏è VISI√ìN:
Ser la tienda online l√≠der en tecnolog√≠a en Guatemala, reconocida por su innovaci√≥n, calidad y compromiso con la satisfacci√≥n del cliente.

üí° VALORES:
- Calidad: Productos originales con garant√≠a del fabricante
- Servicio: Atenci√≥n personalizada y soporte t√©cnico especializado
- Precios Competitivos: Promociones exclusivas y descuentos constantes

üìû INFORMACI√ìN DE CONTACTO:
- Direcci√≥n: Parque El Calvario, Chiquimula, Guatemala, C.A.
- Tel√©fonos: +502 5712-0482, +502 4002-6108, +502 3696-7266
- Correo: soporterjgtechshop@gmail.com
- Horario: Lunes a Viernes 8:00 AM ‚Äì 6:00 PM, S√°bados 9:00 AM ‚Äì 4:00 PM

üë®‚Äçüíº NUESTRO EQUIPO:
- Rudy Eleazar Oloroso Gutierrez ‚Äì CEO & Founder
- Jan Carlos Ren√© Marcos Mar√≠n ‚Äì Director de Estrategia Comercial
- Gerardo Waldemar Garc√≠a V√°squez ‚Äì Director T√©cnico

üí¨ PREGUNTAS FRECUENTES:
1. ¬øC√≥mo hacer un pedido? Realizarlo desde nuestra tienda online, agregar al carrito y pagar de forma segura.
2. ¬øM√©todos de pago? Tarjetas de cr√©dito/d√©bito, transferencias bancarias, pago contra entrega.
3. ¬øTiempo de entrega? 2‚Äì3 d√≠as en capital, 3‚Äì5 d√≠as en interior.
4. ¬øGarant√≠a? S√≠, todos los productos incluyen garant√≠a del fabricante (6 meses a 2 a√±os).

INSTRUCCIONES DE RESPUESTA:
- Responde √öNICAMENTE sobre productos, servicios y procesos de RJG Tech Shop
- Si la consulta es sobre temas NO relacionados, rech√°zala amablemente usando la plantilla
- Proporciona informaci√≥n precisa sobre productos y precios en Quetzales (Q)
- Sugiere visitar la p√°gina web para detalles completos
- Ofrece alternativas similares cuando sea apropiado
- Mant√©n respuestas profesionales y serviciales

${context.products ? `PRODUCTOS DISPONIBLES: ${context.productsSummary || 'Consulta nuestro cat√°logo en l√≠nea'}` : ''}${ragDetails}

Responde de manera √∫til y orientada al cliente, siempre en espa√±ol y con tono profesional.`;

    return {
      role: 'system',
      content: baseInstructions
    };
  }

  /**
   * Procesa una consulta con informaci√≥n RAG
   * @param {string} query - Consulta del usuario
   * @param {Array} relevantDocuments - Documentos relevantes encontrados
   * @returns {Promise<string>} - Respuesta generada
   */
  async generateRAGResponse(query, relevantDocuments = []) {
    try {
      const context = {
        documents: relevantDocuments.map(doc => ({
          title: doc.title,
          content: doc.content.substring(0, 500), // Limitar tama√±o
          category: doc.category,
          type: doc.type
        }))
      };

      const messages = [
        {
          role: 'user',
          content: `Consulta del cliente: ${query}\n\nInformaci√≥n relevante encontrada:\n${relevantDocuments.map((doc, i) => `[${i+1}] ${doc.title}: ${doc.content.substring(0, 300)}...`).join('\n')}`
        }
      ];

      return await this.generateResponse(messages, context);

    } catch (error) {
      console.error('Error generando respuesta RAG:', error);
      throw new Error('Error procesando consulta con documentos de soporte');
    }
  }

  /**
   * Genera sugerencias de respuesta para agentes humanos
   * @param {string} customerQuery - Consulta del cliente
   * @param {Array} conversationHistory - Historial de conversaci√≥n
   * @returns {Promise<Array>} - Array de sugerencias
   */
  async generateResponseSuggestions(customerQuery, conversationHistory = []) {
    try {
      const messages = [
        {
          role: 'system',
          content: 'Eres un asistente que genera sugerencias de respuesta para agentes de atenci√≥n al cliente. Genera 3 respuestas cortas y √∫tiles diferentes para la consulta del cliente.'
        },
        {
          role: 'user',
          content: `Consulta del cliente: ${customerQuery}\n\nHistorial de conversaci√≥n:\n${conversationHistory.slice(-3).map(m => `${m.sender}: ${m.content}`).join('\n')}`
        }
      ];

      const response = await this.client.chat.completions.create({
        model: this.model,
        messages,
        max_tokens: 300,
        temperature: 0.8,
        n: 3 // Generar 3 sugerencias
      });

      return response.choices.map(choice => choice.message.content.trim());

    } catch (error) {
      console.error('Error generando sugerencias:', error);
      return [
        'Lo siento, no pude generar sugerencias en este momento.',
        'Un agente especializado te ayudar√° con tu consulta.',
        'Gracias por tu paciencia mientras te conectamos con soporte.'
      ];
    }
  }

  /**
   * Clasifica la intenci√≥n de la consulta del usuario
   * @param {string} message - Mensaje del usuario
   * @returns {Promise<Object>} - Objeto con intenci√≥n y confianza
   */
  async classifyIntent(message) {
    try {
      console.log('OpenAIClient: Clasificando intenci√≥n para mensaje:', message.substring(0, 50));

      const messages = [
        {
          role: 'system',
          content: `Clasifica la intenci√≥n del mensaje del cliente en una de estas categor√≠as:

          CATEGOR√çAS DE CONSULTA:
          - consulta_producto: Preguntas sobre productos espec√≠ficos o cat√°logo general
          - consulta_pedido: Seguimiento de pedidos o problemas con √≥rdenes existentes
          - consulta_tecnica: Problemas t√©cnicos o soporte t√©cnico
          - consulta_devolucion: Pol√≠ticas de devoluci√≥n o cambios
          - consulta_envio: Informaci√≥n sobre env√≠os y entregas
          - saludo: Saludos o conversaciones casuales
          - queja: Quejas o problemas con el servicio

          CATEGOR√çAS DE COMPRA CONVERSACIONAL:
          - compra_producto: Quiere comprar un producto espec√≠fico que mencion√≥
          - agregar_carrito: Quiere agregar productos al carrito de compra
          - ver_carrito: Quiere ver el contenido del carrito
          - modificar_carrito: Quiere cambiar cantidades o remover productos del carrito
          - proceder_pago: Quiere proceder al pago o finalizar la compra
          - confirmar_compra: Confirmaci√≥n de detalles antes de comprar
          - cancelar_compra: Quiere cancelar el proceso de compra

          OTRAS:
          - otra: Cualquier otra consulta que no encaje en las categor√≠as anteriores

          REGLAS ESPEC√çFICAS PARA COMPRA:
          - Si menciona un producto espec√≠fico y dice "comprar", "adquirir", "me interesa", usa "compra_producto"
          - Si dice "agregar al carrito", "a√±adir al carrito", usa "agregar_carrito"
          - Si dice "ver carrito", "qu√© tengo en el carrito", usa "ver_carrito"
          - Si dice "proceder al pago", "pagar", "checkout", usa "proceder_pago"
          - Si pregunta por precios o disponibilidad con intenci√≥n clara de compra, usa "compra_producto"

          Responde √∫nicamente con el formato JSON: {"intent": "categoria", "confidence": 0.95}`
        },
        {
          role: 'user',
          content: message
        }
      ];

      console.log('OpenAIClient: Enviando solicitud de clasificaci√≥n a OpenAI...');
      const response = await this.client.chat.completions.create({
        model: this.model,
        messages,
        max_tokens: 10, // Solo 10 tokens para respuestas ultra-r√°pidas
        temperature: 0.1, // M√°s determinista para clasificaci√≥n
        response_format: { type: "json_object" }
      });

      console.log('OpenAIClient: Respuesta de clasificaci√≥n recibida');
      const result = JSON.parse(response.choices[0]?.message?.content || '{"intent": "otra", "confidence": 0.5}');

      return {
        intent: result.intent || 'otra',
        confidence: result.confidence || 0.5
      };

    } catch (error) {
      console.error('OpenAIClient: Error clasificando intenci√≥n:', error);
      return {
        intent: 'otra',
        confidence: 0.5
      };
    }
  }

  /**
   * Verifica el estado de la API de OpenAI
   * @returns {Promise<boolean>} - True si la API est√° disponible
   */
  async checkHealth() {
    try {
      await this.client.models.list();
      return true;
    } catch (error) {
      console.error('Error verificando salud de OpenAI:', error);
      return false;
    }
  }
}

// Factory function para crear cliente OpenAI con configuraci√≥n
export const createOpenAIClient = (apiKey) => {
  return new OpenAIClient(apiKey);
};
